{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e48b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qrandom\n",
    "import torch \n",
    "from torch import tensor\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "relu = nn.functional.relu\n",
    "softmax = nn.functional.softmax\n",
    "from torch.nn.functional import cross_entropy\n",
    "from pathlib import Path\n",
    "import os, shutil\n",
    "from os import listdir\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import random\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a513500",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.current_device(),\n",
    "torch.cuda.device(0),\n",
    "torch.cuda.get_device_name(0))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3212e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    axs.set_title(title or 'Spectrogram (db)')\n",
    "    axs.set_ylabel(ylabel)\n",
    "    axs.set_xlabel('frame')\n",
    "    im = axs.imshow(librosa.power_to_db(spec), origin='lower', aspect=aspect)\n",
    "    if xmax:\n",
    "        axs.set_xlim((0, xmax))\n",
    "    fig.colorbar(im, ax=axs)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bd2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs_dir_true = Path(r\"C:\\Users\\g_bab\\Downloads\\botwTRAINING\").expanduser()\n",
    "true_specs = []\n",
    "for z in range(len(listdir(specs_dir_true))):\n",
    "    try:\n",
    "        im = np.load(os.path.join(specs_dir_true, \"spec\"+str(z+1)+\".npy\"))\n",
    "        true_specs.append(im)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44886f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(true_specs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57acc847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test if it loaded correctly\n",
    "toaudio_list = []\n",
    "for sample in true_specs[:100]:                #first 100 melspecs (np arrays) in a list\n",
    "    #sample = sample.detach().numpy()\n",
    "    toaudio_list.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2f9760",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_amp_values = []\n",
    "for melspec in toaudio_list:\n",
    "    audio_array = librosa.feature.inverse.mel_to_audio(melspec, sr = 16000)\n",
    "    list_amp_values += list(audio_array)\n",
    "playback = np.asarray(list_amp_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b9783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(playback, rate=44100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e082e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(true_specs[1]))\n",
    "plot_spectrogram(true_specs[1])\n",
    "torch_test = torch.from_numpy(true_specs[1])\n",
    "plot_spectrogram(torch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ee763",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = np.shape(true_specs[1])[1]/2\n",
    "print(split)\n",
    "half1 = true_specs[1][:, :split]\n",
    "half2 = true_specs[1][:, split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe70a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "listspecs_torch = []\n",
    "for i in true_specs:\n",
    "    listspecs_torch.append(torch.from_numpy(i))\n",
    "print(len(listspecs_torch))\n",
    "print(len(true_specs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce3945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#noise_shape = (100,)\n",
    "epochs = 50   #change to 150\n",
    "lr = 2e-4\n",
    "batch_size = 1 #change to 30 if possible\n",
    "height = 577\n",
    "length = 123\n",
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f62e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(70971, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.activation = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 70971)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return nn.Sigmoid()(x)\n",
    "\n",
    "\n",
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(123, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 70971)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = x.view(-1, 577, 123)\n",
    "        return nn.Tanh()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e8f5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator().to(device)\n",
    "D = discriminator().to(device)\n",
    "\n",
    "G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "D_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca4174",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7065eb9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    idxs = np.arange(len(listspecs_torch))\n",
    "    np.random.shuffle(idxs)\n",
    "    for batch_cnt in range(len(listspecs_torch)//batch_size):\n",
    "        batch_indices = idxs[batch_cnt*batch_size : (batch_cnt + 1)*batch_size]\n",
    "        batch = [listspecs_torch[index] for index in batch_indices]\n",
    "        \n",
    "        imgs = torch.stack(batch)\n",
    "        \n",
    "        # Training the discriminator\n",
    "        # Real inputs are actual images of BOTW dataset\n",
    "        # Fake inputs are from the generator\n",
    "        # Real inputs should be classified as 1 and fake as 0\n",
    "        \n",
    "        real_inputs = imgs.to(device)\n",
    "        #print(\"real inputs: \", real_inputs.shape)\n",
    "        real_outputs = D(real_inputs)\n",
    "        #print(\"guess on real outputs: \", real_outputs.shape)\n",
    "        real_label = torch.ones(real_inputs.shape[0], 1).to(device)\n",
    "        #print(\"label for real: \", real_label.shape)\n",
    "        \n",
    "        noise = (torch.rand(real_inputs.shape[0], 123) - 0.5) / 0.5\n",
    "        #print(\"noise shape: \", noise.shape)\n",
    "        noise = noise.to(device)\n",
    "        fake_inputs = G(noise)\n",
    "        #print(\"generated fake inputs: \", fake_inputs.shape)\n",
    "        fake_outputs = D(fake_inputs)\n",
    "        #print(\"discriminator guess on fake inputs : \", fake_outputs.shape)\n",
    "        fake_label = torch.zeros(fake_inputs.shape[0], 1).to(device)\n",
    "        #print(\"label for fake: \", fake_label.shape)\n",
    "        \n",
    "        outputs = torch.cat((real_outputs, fake_outputs), 0)\n",
    "        targets = torch.cat((real_label, fake_label), 0)\n",
    "\n",
    "        D_loss = loss(outputs, targets)\n",
    "        D_optimizer.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "        # Training the generator\n",
    "        # For generator, goal is to make the discriminator believe everything is 1\n",
    "        noise = (torch.rand(real_inputs.shape[0], 123)-0.5)/0.5\n",
    "        noise = noise.to(device)\n",
    "        #print(\"noise for generator shape: \", noise.shape)\n",
    "        fake_inputs = G(noise)\n",
    "        #print(\"generated inputs:\", fake_inputs.shape)\n",
    "        fake_outputs = D(fake_inputs)\n",
    "        #print(\"guesses on fake inputs:\", fake_outputs.shape)\n",
    "        fake_targets = torch.ones([fake_inputs.shape[0], 1]).to(device)\n",
    "        #print(\"ideal guesses on fake inputs: \", fake_targets.shape)\n",
    "        G_loss = loss(fake_outputs, fake_targets)\n",
    "        G_optimizer.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "        if batch_cnt % 500 == 0:\n",
    "            print('Epoch {} Iteration {}: discriminator_loss {:.3f} generator_loss {:.3f}'.format(epoch, batch_cnt, D_loss.item(), G_loss.item()))\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save(G, r\"C:\\Users\\g_bab\\Downloads\\saved_musicGAN\\generator_epoch_{}.pth\".format(epoch))\n",
    "        print('Model saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b090e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(G, r\"C:\\Users\\g_bab\\Downloads\\saved_musicGAN\\generator_epoch_{}.pth\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc04032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#credit to sbalian for qrandom\n",
    "\n",
    "list_products = []\n",
    "for i in range(100):                #first 100 melspecs (np arrays) in a list\n",
    "    batch = []\n",
    "    for i in range(batch_size):\n",
    "        qrandomarray = np.zeros(577 * 123)\n",
    "    \n",
    "        #for q in range(577 * 123):\n",
    "            #qrandomarray[q] = qrandom.random()\n",
    "        for q in range(577 * 123):\n",
    "            qrandomarray[q] = random.random()\n",
    "        \n",
    "        qrandomarray = np.reshape(qrandomarray, (577, 123))\n",
    "        qrandomarray = (qrandomarray - 0.5) / 0.5\n",
    "        batch.append(qrandomarray)\n",
    "    batch = np.stack(batch)\n",
    "    batch = batch.astype(np.float32)\n",
    "    batch = torch.from_numpy(batch)\n",
    "    batch = batch.to(device)\n",
    "    \n",
    "    product = G(batch)\n",
    "    \n",
    "    detached = product.to(\"cpu\").detach().numpy()\n",
    "    list_products.append(detached)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9fd9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D_loss.item(), G_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db89129",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_products[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a0739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_amp_values = []\n",
    "for melspec in list_products:\n",
    "    for i in range(len(melspec[0])):\n",
    "        audio_array = librosa.feature.inverse.mel_to_audio(melspec, sr = 16000)\n",
    "        list_amp_values += list(audio_array)\n",
    "playback = np.asarray(list_amp_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f591556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(playback, rate=44100)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
